{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZLxlGoD0pLM",
        "outputId": "096564da-4687-4c00-ffe9-07b598b9bf30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/.shortcut-targets-by-id/18oPzXa_o2Y_k8Bcbz3FNVsqteJ0Pt29Y/Final Project\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import sys\n",
        "path = '/content/drive/My Drive/Final Project'\n",
        "sys.path.append(path)\n",
        "\n",
        "%cd $path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jocgWmH20wBf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hLd0yqsS1jLc",
        "outputId": "36873dc7-a006-4ae7-da96-d78a1f7b86f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Tweet\n",
              "0               Cowboy riding the rocket no problemo\n",
              "1    Single camera view of the 40 meter rocket hover\n",
              "2  Then we took him for a ride: 40 meter hover fl...\n",
              "3  To provide a little perspective on the size of...\n",
              "4  Very much agree with this great review of Chas..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61e82118-b44f-41d7-9ad0-51927ecbd6ae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cowboy riding the rocket no problemo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Single camera view of the 40 meter rocket hover</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Then we took him for a ride: 40 meter hover fl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>To provide a little perspective on the size of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Very much agree with this great review of Chas...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61e82118-b44f-41d7-9ad0-51927ecbd6ae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-61e82118-b44f-41d7-9ad0-51927ecbd6ae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-61e82118-b44f-41d7-9ad0-51927ecbd6ae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "cleaned_tweets = pd.read_csv(\"data/cleaned_elon.csv\").drop([\"Unnamed: 0\"], axis=1)\n",
        "cleaned_tweets.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKe4w4Lxzb-M",
        "outputId": "d7f32db2-f572-4dea-d8f3-26113165e5d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12622"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "len(cleaned_tweets)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change this constant to determine the number of randomly sampled (without replacement) tweets we use from the dataset\n",
        "NUM_TWEETS = 500"
      ],
      "metadata": {
        "id": "YjWqDwLrRyp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZDwxrlf01oC",
        "outputId": "98e946c1-ed6e-44f3-9f67-462c0440830d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2333"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "tweets = random.sample(list(cleaned_tweets[\"Tweet\"]), NUM_TWEETS)\n",
        "vectorizer = CountVectorizer()\n",
        "## This one hot encodes the words and records all the corresponding words to their index in vectorizer.get_feature_names_out()\n",
        "X = vectorizer.fit_transform(tweets)\n",
        "len(vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSdCgaBg2eSw",
        "outputId": "f9c99d41-f049-4278-b8af-73170c5a0595"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random feature/word: market\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "print(f\"Random feature/word: {feature_names[random.randint(0, len(feature_names))]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lB4mXQ272mDY",
        "outputId": "302a74d3-7e70-4135-e1b9-a8ed42361d1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Without', 'the', 'removal', 'fee,', 'Tesla', 'Solar', 'is', 'unequivocally', 'a', 'guaranteed,', 'instant', 'money', 'printer,', 'producing', '$300', 'to', '$1000', 'per', 'year', '(in', 'after', 'tax', 'income!)']\n",
            "Length of tweet in words: 23\n",
            "22\n"
          ]
        }
      ],
      "source": [
        "randind = random.randint(0, len(tweets))\n",
        "words = tweets[randind].split(\" \")\n",
        "print(words)\n",
        "print(f\"Length of tweet in words: {len(words)}\")\n",
        "print(X.toarray()[randind].sum())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(tweets))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIhjNW8orQSD",
        "outputId": "a9844dfc-df7c-4a66-96e8-435fbc8da524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfwKeC7-4SsE",
        "outputId": "f2ca07ee-372d-4ff4-e473-11e00fe1ffa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdhF46SC2_v3",
        "outputId": "a9808f7c-5a79-408d-f309-b0238315e485"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "en_stopws = stopwords.words('english')\n",
        "\n",
        "corpus = \" \".join(tweets)\n",
        "corpus = corpus.lower()\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "tokens = tokenizer.tokenize(corpus)\n",
        "tokens = [token for token in tokens if token not in en_stopws]\n",
        "fdist = FreqDist(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RR9N1LHBhA0l"
      },
      "source": [
        "The following shows the 100 most common words. This gives us a preview of the types of words that appear most frequently and thus will be likely generated by the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAoIvUfn3bAa",
        "outputId": "f8cf0d0c-e8df-44fd-f2b6-16ce0cbb2844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('tesla', 102), ('amp', 70), ('model', 50), ('rocket', 25), ('first', 23), ('falcon', 22), ('new', 22), ('like', 21), ('launch', 20), ('good', 20), ('car', 19), ('3', 18), ('time', 17), ('w', 16), ('spacex', 16), ('x', 16), ('space', 14), ('9', 14), ('long', 14), ('dragon', 14), ('mars', 14), ('today', 13), ('called', 13), ('team', 12), ('year', 12), ('test', 12), ('us', 12), ('solar', 12), ('next', 11), ('love', 11), ('landing', 11), ('real', 11), ('autopilot', 11), ('much', 11), ('station', 11), ('people', 11), ('company', 10), ('1', 10), ('california', 10), ('coming', 10), ('soon', 10), ('awesome', 10), ('day', 10), ('review', 10), ('need', 10), ('cars', 10), ('true', 10), ('also', 10), ('video', 9), ('article', 9), ('way', 9), ('great', 9), ('world', 9), ('many', 9), ('would', 9), ('flight', 9), ('btw', 9), ('show', 9), ('2', 9), ('worth', 9), ('takes', 8), ('high', 8), ('know', 8), ('right', 8), ('ship', 8), ('tank', 8), ('stage', 8), ('want', 8), ('la', 8), ('still', 8), ('almost', 8), ('better', 8), ('going', 8), ('made', 8), ('tax', 8), ('drive', 8), ('go', 8), ('one', 8), ('tomorrow', 8), ('ai', 8), ('actually', 8), ('important', 7), ('5', 7), ('mission', 7), ('little', 7), ('thanks', 7), ('make', 7), ('driving', 7), ('system', 7), ('live', 7), ('design', 7), ('believe', 7), ('years', 7), ('end', 7), ('cape', 7), ('well', 7), ('point', 7), ('think', 7), ('big', 7), ('even', 7)]\n"
          ]
        }
      ],
      "source": [
        "print(fdist.most_common(100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEIJ2SNiheCc"
      },
      "source": [
        "Let's clean some of the data. We removed most of the emojis in the preprocessing with a regex, but there are some still missing. We will remove them here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ie3UdlMf6Efe",
        "outputId": "0ab73432-e7c0-4cbe-9bc5-94422d8c3ad7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total chars: 90\n"
          ]
        }
      ],
      "source": [
        "chars = sorted(list(set(''.join(tweets))))\n",
        "print('total chars:', len(chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Be_c1oz8ejPc",
        "outputId": "e7e851b8-8cdf-49d3-af07-54879dd65532"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' ', '!', '\"', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '~', '≈ç', '‚Äì', '‚Äô', '‚Äú', '‚Äù', '‚Ä¶', 'ü§ò', 'ü§£']\n"
          ]
        }
      ],
      "source": [
        "print(chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4Qv2IWmuG5a"
      },
      "outputs": [],
      "source": [
        "# to_exclude = ['ü§î', 'ü§ñ', 'ü§ó', 'ü§ò', 'ü§£', 'ü§Ø', 'ü§π', 'ü•Å', 'ü•á', 'ü•ú', 'ü•µ', '\\U0001f979', 'ü¶ä', 'üßÄ', 'üßÅ', 'üßê', 'üßô', 'üßõ', 'üß†', 'üß¶', 'üß®', 'üß≤', 'ü©∏']\n",
        "# for i in range(len(tweets)):\n",
        "#   for char in to_exclude:\n",
        "#     if char in tweets[i]:\n",
        "#       tweets[i] = tweets[i].replace(char, \"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_characters = [' ', '!', '\"', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']"
      ],
      "metadata": {
        "id": "Mk4bGMols1CO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We want to limit the tweets to alphanumeric characters and general punctuation\n",
        "for i in range(len(tweets)):\n",
        "  for char in valid_characters:\n",
        "    if char not in tweets[i]:\n",
        "      tweets[i] = tweets[i].replace(char, \"\")"
      ],
      "metadata": {
        "id": "HSkD85EFs60i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GG9ztcXue26-",
        "outputId": "49238d7a-03ad-4b38-bf2a-5d03ca909c0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total chars: 90\n"
          ]
        }
      ],
      "source": [
        "chars = sorted(list(set(''.join(tweets))))\n",
        "print('total chars:', len(chars))\n",
        "num_chars = len(chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOlDSv3Evtkf"
      },
      "outputs": [],
      "source": [
        "corpus = \" \".join(tweets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cg6dLoGPxJHQ"
      },
      "outputs": [],
      "source": [
        "# create idx2char dict and char2idx dict\n",
        "char2idx = dict((c, i) for i, c in enumerate(chars))\n",
        "idx2char = dict((i, c) for i, c in enumerate(chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xEB0o6AxQQN"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 32\n",
        "max_seq_length = 40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VbR9uoyxV9Z"
      },
      "outputs": [],
      "source": [
        "# This allows for reproducability of the training.\n",
        "tf.compat.v1.reset_default_graph()\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHA1hCXWxWYN",
        "outputId": "dad89400-d557-48c8-cac1-2b7786d7d05a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43227\n"
          ]
        }
      ],
      "source": [
        "sentences = []\n",
        "next_chars = []\n",
        "# sliding window of shifted over sequences\n",
        "for i in range(0, len(corpus)-max_seq_length):\n",
        "  seq_in = corpus[i:i+max_seq_length]\n",
        "  seq_out = corpus[i+max_seq_length]\n",
        "  sentences.append([char2idx[i] for i in seq_in])\n",
        "  next_chars.append(char2idx[seq_out])\n",
        "\n",
        "n_sentences = len(sentences)\n",
        "print(n_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BklOP3H1g7jY",
        "outputId": "00a1a20d-9d58-4fa0-ae4e-cfc213e68f4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1729080\n"
          ]
        }
      ],
      "source": [
        "# spread out sequences to form one long array of characters\n",
        "X = [ch for sentence in sentences for ch in sentence]\n",
        "print(len(X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdJAkEp-hO-w"
      },
      "outputs": [],
      "source": [
        "X = keras.utils.to_categorical(X, num_classes=num_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ivf6zu_FhSo6",
        "outputId": "e3dc331a-682b-43d4-f27a-b2ece473682e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1729080, 90)\n"
          ]
        }
      ],
      "source": [
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoiRsK1ExWba",
        "outputId": "373faf66-3940-47f6-b8d1-33bc14944808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(43227, 40, 90)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(43227, 90)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "\n",
        "X = np.reshape(X, (n_sentences, max_seq_length, len(X[0])))\n",
        "print(X.shape)\n",
        "\n",
        "# 67035 entries with each entry being 40 by 93\n",
        "# 40 being sequence length and 93 being size of each one hot encoded vector (vocabulary)\n",
        "\n",
        "y = keras.utils.to_categorical(next_chars, num_classes=len(chars))\n",
        "y.shape\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H37pKWmmiLFR"
      },
      "source": [
        "The sequence length is determined. The way the model is trained is a where X=(40 characters of text) and y=(The next character). So the model is generating the character with the highest probability given the context of the previous 40."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_idKKxUZxWe0"
      },
      "outputs": [],
      "source": [
        "\n",
        "# define tf data and batch accordingly\n",
        "# train val split\n",
        "data_lstm = tf.data.Dataset.from_tensor_slices((X, y))\n",
        "data_lstm = data_lstm.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "TRAIN_SIZE = int(0.85 * (n_sentences//BATCH_SIZE))\n",
        "data_lstm = data_lstm.shuffle(buffer_size= BUFFER_SIZE, reshuffle_each_iteration=False)\n",
        "train_lstm = data_lstm.take(TRAIN_SIZE)\n",
        "val_lstm = data_lstm.skip(TRAIN_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwoinGXLxWiT"
      },
      "outputs": [],
      "source": [
        "train_lstm = train_lstm.cache()\n",
        "\n",
        "val_lstm = val_lstm.cache()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.compat.v1.data.get_output_shapes(data_lstm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2IZBmD0rogs",
        "outputId": "1c2bb87a-a700-4fa2-86fd-1d47acf7e9d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(TensorShape([32, 40, 90]), TensorShape([32, 90]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5KVEBmMxj-t",
        "outputId": "e70f4f9f-21f7-4a4f-d15c-718662cf54e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (32, 40, 1024)            4567040   \n",
            "                                                                 \n",
            " dropout (Dropout)           (32, 40, 1024)            0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (32, 1024)                8392704   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (32, 1024)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (32, 90)                  92250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,051,994\n",
            "Trainable params: 13,051,994\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def build_lstm(rnn_units, dropout, batch_size):\n",
        "  lstm = Sequential()\n",
        "  lstm.add(layers.LSTM(rnn_units, return_sequences=True, batch_input_shape=(batch_size, max_seq_length, num_chars)))\n",
        "  lstm.add(layers.Dropout(dropout))\n",
        "  lstm.add(layers.LSTM(rnn_units))\n",
        "  lstm.add(layers.Dropout(dropout))\n",
        "  lstm.add(layers.Dense(num_chars, activation='softmax'))\n",
        "\n",
        "  return lstm\n",
        "\n",
        "lstm = build_lstm(1024, 0.1, BATCH_SIZE)\n",
        "lstm.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYcOiDIsxkKc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "959970a2-07d3-4c62-d05c-506f96e9f8cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1147/1147 - 60s - loss: 2.9062 - val_loss: 2.5685 - 60s/epoch - 52ms/step\n",
            "Epoch 2/10\n",
            "1147/1147 - 49s - loss: 2.4602 - val_loss: 2.3103 - 49s/epoch - 43ms/step\n",
            "Epoch 3/10\n",
            "1147/1147 - 49s - loss: 2.2781 - val_loss: 2.1325 - 49s/epoch - 43ms/step\n",
            "Epoch 4/10\n",
            "1147/1147 - 50s - loss: 2.1124 - val_loss: 1.9675 - 50s/epoch - 44ms/step\n",
            "Epoch 5/10\n",
            "1147/1147 - 49s - loss: 1.9291 - val_loss: 1.8086 - 49s/epoch - 43ms/step\n",
            "Epoch 6/10\n",
            "1147/1147 - 50s - loss: 1.7001 - val_loss: 1.6559 - 50s/epoch - 44ms/step\n",
            "Epoch 7/10\n",
            "1147/1147 - 49s - loss: 1.4073 - val_loss: 1.5415 - 49s/epoch - 43ms/step\n",
            "Epoch 8/10\n",
            "1147/1147 - 49s - loss: 1.0796 - val_loss: 1.4353 - 49s/epoch - 43ms/step\n",
            "Epoch 9/10\n",
            "1147/1147 - 50s - loss: 0.7755 - val_loss: 1.3538 - 50s/epoch - 43ms/step\n",
            "Epoch 10/10\n",
            "1147/1147 - 50s - loss: 0.5452 - val_loss: 1.2724 - 50s/epoch - 43ms/step\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "# def perplexity(labels, preds):\n",
        "#     return keras.backend.exp(tf.keras.losses.categorical_crossentropy(labels, preds))\n",
        "\n",
        "# cc takes one hot encoded\n",
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.categorical_crossentropy(labels, logits)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-4, epsilon=1e-8)\n",
        "  \n",
        "lstm.compile(optimizer=optimizer, loss=loss) \n",
        "\n",
        "history_lstm = lstm.fit(train_lstm, epochs=epochs, validation_data=val_lstm, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpNfoD2jeheT"
      },
      "outputs": [],
      "source": [
        "lstm.save_weights('lstm_weights_10_epoch.hdf5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJogZqSWxkO0"
      },
      "outputs": [],
      "source": [
        "# build model of batch 1 for evaluation\n",
        "lstm1 = build_lstm(1024, 0.2, 1)\n",
        "lstm1.load_weights('lstm_weights_10_epoch.hdf5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buIQoSOCxude"
      },
      "outputs": [],
      "source": [
        "# sourced from keras tutorial\n",
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTYZJu8jxz2t",
        "outputId": "3da27cc0-9d78-4b2c-ebc7-c8f61775b6e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generating with: We plan on releasing a new fleet of Tesl\n",
            "0.25\n",
            "Temperature: 0.25\n",
            "We plan on releasing a new fleet of Tesla is anceally of not searce computies of Falcon book most plodictulating in the word ‚Ä¶ Test to be la\n",
            "0.5\n",
            "Temperature: 0.5\n",
            "We plan on releasing a new fleet of Tesla is also loget a campond a complece to production a cal on the launch pod Sharkess arvitheraling wo\n",
            "0.75\n",
            "Temperature: 0.75\n",
            "We plan on releasing a new fleet of Tesla is ancechould bowehtatedrw in Sepace &omp; govilatesy to beal. Model S ans commuch in the pad &amp\n",
            "1.0\n",
            "Temperature: 1.0\n",
            "We plan on releasing a new fleet of Tesla deploded only Scancentises. A cripizats ramp; busigitar. Drains only bake. Tesla good enginear sol\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# generating w/ random start tweet\n",
        "start_index = random.randint(0, len(tweets))\n",
        "for temperature in np.arange(0.25, 1.25, 0.25):\n",
        "  generated = ''\n",
        "  sentence = \"We plan on releasing a new fleet of Tesl\"#tweets[start_index][:max_seq_length]\n",
        "  if temperature == 0.25:\n",
        "    print('generating with: ' + sentence)\n",
        "  generated += sentence\n",
        "  print(temperature)\n",
        "  for i in range(100):\n",
        "    test = [char2idx[i] for i in sentence]\n",
        "    test = keras.utils.to_categorical(test, num_classes=num_chars)\n",
        "    test = tf.expand_dims(test, 0)\n",
        "    preds = lstm1.predict(test, verbose=0)[0]\n",
        "    next_index = sample(preds, temperature)\n",
        "    next_char = idx2char[next_index]\n",
        "    sentence = sentence[1:] + next_char\n",
        "    generated += next_char\n",
        "  print(f\"Temperature: {temperature}\")\n",
        "  print(generated)\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SVlo26-kPXr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}